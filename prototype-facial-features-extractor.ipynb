{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = cv2.imread(\"sample.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = detector(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect facial landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "facial_landmarks_image = np.zeros(input_image.shape, np.uint8)\n",
    "\n",
    "for face in faces:\n",
    "    # Get the facial landmarks for the detected face\n",
    "    landmarks = predictor(gray, face)\n",
    "\n",
    "    # Loop through the landmarks and extract their (x, y) coordinates\n",
    "    for i in range(68):  # There are 68 landmarks in the model\n",
    "        x, y = landmarks.part(i).x, landmarks.part(i).y\n",
    "\n",
    "        # Draw a point on the image at each landmark\n",
    "        cv2.putText(facial_landmarks_image, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "# Save or display the image with landmarks\n",
    "cv2.imwrite(\"output/facial_landmarks_image.jpg\", facial_landmarks_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract eye regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the indices for the eye landmarks (assuming landmarks are ordered correctly)\n",
    "left_eye_x = landmarks.part(36).x  # Leftmost point of the left eye\n",
    "left_eye_y = min(landmarks.part(37).y, landmarks.part(38).y)  # Topmost point of the left eye\n",
    "left_eye_width = landmarks.part(39).x - left_eye_x  # Width of the left eye\n",
    "left_eye_height = max(landmarks.part(41).y, landmarks.part(40).y) - left_eye_y  # Height of the left eye\n",
    "\n",
    "right_eye_x = landmarks.part(42).x  # Leftmost point of the right eye\n",
    "right_eye_y = min(landmarks.part(43).y, landmarks.part(44).y)  # Topmost point of the right eye\n",
    "right_eye_width = landmarks.part(45).x - right_eye_x  # Width of the right eye\n",
    "right_eye_height = max(landmarks.part(47).y, landmarks.part(46).y) - right_eye_y  # Height of the right eye\n",
    "\n",
    "# Crop out the left and right eye regions from the input image\n",
    "left_eye_region = input_image[left_eye_y:left_eye_y + left_eye_height, left_eye_x:left_eye_x + left_eye_width]\n",
    "right_eye_region = input_image[right_eye_y:right_eye_y + right_eye_height, right_eye_x:right_eye_x + right_eye_width]\n",
    "\n",
    "# Display or save the cropped eye regions\n",
    "cv2.imwrite(\"output/left_eye_region.jpg\", left_eye_region)\n",
    "cv2.imwrite(\"output/right_eye_region.jpg\", right_eye_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process eye regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_eye_region_hsv = cv2.cvtColor(left_eye_region, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# left_eye_region_hsv[:, :, 1] = 125\n",
    "# left_eye_region_hsv[:, :, 2] = 255\n",
    "\n",
    "cv2.imwrite(\"output/left_eye_region_hsv.jpg\", left_eye_region_hsv[:, :, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facial_features_extractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
